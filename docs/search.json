[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Bradford Johnson",
    "section": "",
    "text": "Welcome! I‚Äôm an explorer of many realms: data analytics, IT, and sociology. I‚Äôm a self-taught R programmer, and visualization designer.\nAlso, I love dogs; Roxyüêï & Ollieüêï.\n\nSpecialtiesSkillsHobbies\n\n\n\nData Visualization & Dashboard Development\nData Cleaning & Statistical Analysis\nReport Generation & Data Story Telling\n\n\n\n\n\n\nSQL\nR\nPython\n\n\nExcel\nTableau\nQuarto\n\n\nWeb Scraping\nStatistical Analysis\nData Wrangling\n\n\nData Visualization\nGitHub\nResearch Design\n\n\n\n\n\n\nüë®‚Äçüíª Programming\nüå≥‚õ∞Ô∏è Hiking\nüì∏ Photography\nüóìÔ∏è TidyTuesday! - A weekly social data project in R\n\n\n\n\n\nEducation\n\n\nData Analytics | Thinkful | 2022\nB.A. Sociology | Winthrop University | 2021"
  },
  {
    "objectID": "blog/01-blog-intro/index.html",
    "href": "blog/01-blog-intro/index.html",
    "title": "Why Quarto?",
    "section": "",
    "text": "Some describe it as magic, and others have not used Quarto. I was introduced to Quarto as it was added to RStudio in an update in July 2022. Once I saw Thomas Mock‚Äôs talk Quarto for the curious I knew I had to explore Quarto. I would go into detail about the technical aspects of what Quarto does, but why not show what it can do? This very website is built with Quarto, and so is Quarto‚Äôs website.\n\n\nI built this site using RStuido as the environment, but if you prefer something like `VS Code` then you can use the Quarto extension. My site‚Äôs code lives in it‚Äôs own GitHub repository which you can view by clicking the code icon on the right side of the navigation bar‚Ä¶or here. I use GitHub for version control, but also host my site with GitHub Pages. I bought my domain name and it was simple to get it up and running from there.\nWhen I want to do some sprucing up to my site I create a new branch and edit the branch. Once I edit the files and code I will render my site in RStudio and then push the commits. Finally I will do a pull request and merge the branch with my main branch. GitHub Actions will then publish the site, however you do not need to do the branching. A single commit on the main branch will trigger GitHub Actions and update your site automatically. This means you can edit and publish the edits all from the code editor!\n\n\n\nQuarto documents .qmd are the files that you edit, and they have YAML code blocks at the top of the document that let you control different features such as: titles, what the output is, and many other controls. The output control is very special as you can render a file as .html output for webpages and many other formats! Do you need a slideshow? A .pdf report? A book?\nHere is what the YAML looks like for this blog post!\n---\ntitle: \"Why Quarto?\"\ndate: \"3/03/2023\"\ndescription: \"Why I build my website with Quarto...\"\ncategories: \"Quarto\"\nformat: html\neditor: visual\nhighlight-style: github\n---\nYou can create and run code chunks, this allows you to create reports, KPI dashboards, articles and so much more. I would describe Quarto as a way to share data analytics or knowledge in a meaningful and completely customized way. It is easily integrated into workflows, and you do not even have to know R. You can use Quarto with Python, Julia, Observable or R. Have a team of R users and Python users? They all can work together with Quarto, and even within the same document‚Ä¶\n\n\n\npaste0(R.Version()[c(\"major\",\"minor\")], collapse = \".\")\n\n[1] \"4.2.2\"\n\n\n\n\n\n\nimport sys\nprint(\"Python version\")\n\nPython version\n\nprint (sys.version)\n\n3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]\n\n\n\n\n\n#| warning: false\n#| message: false\n\nlibrary(tidyverse)\n\nggplot(data = iris, aes( x = Sepal.Length, y = Sepal.Width,\n                         shape = Species, color = Species)) +\n  geom_point()\n\n\n\n\n\nDid you notice in the code chunk the #|‚Äôs? This is how you tell the chunk how to behave, I stopped warnings and messages in that chunk. You can use Quarto as Jupyter notebooks or R Markdown notebooks and render those notebooks to your desired output. Another thing is that you can use a visual editor, all within your development environment, making it that much easier to make some beautiful deliverables or notes for yourself!"
  },
  {
    "objectID": "blog/01-blog-intro/index.html#so-why-quarto",
    "href": "blog/01-blog-intro/index.html#so-why-quarto",
    "title": "Why Quarto?",
    "section": "So why Quarto?",
    "text": "So why Quarto?\n\nLanguage agnostic for data teams\nHigh quality outputs, and many types of outputs\nFlexible workflows and ease of use\nIt is fun, and works via magic\n\nIf you are still not convinced‚Ä¶\n\nI encourage you to look into Quarto as it would take a dedicated blog to really do Quarto justice, as one post can only cover so much‚Ä¶\nHere‚Äôs a Quarto blog made with Quarto, by the Quarto team!"
  },
  {
    "objectID": "blog/02-r/index.html",
    "href": "blog/02-r/index.html",
    "title": "Teaching myself R",
    "section": "",
    "text": "I was first exposed to R in a statistics course in college. Having some previous coding experiences with HTML, CSS, and C++ I was able to pick up R pretty quickly. In this course we only used a couple functions as an aid for our course work. Essentially we manually created vectors, found the standard deviation, conducted T-tests and Chi-squared tests. We never made visuals or really went deeper into R. This class was remote and during COVID-19, so instead of turning in notes or homework physically we emailed in pictures of our handwritten work.\nThis was fine but I did not like drawing box plots manually. I ended up finding a tutorial for making a box plot with R, and I started turning in my drawings by exporting the .png files and emailing them. My professor thought I was an expert data analyst and we would talk data after our class meetings.\nHere is my first visual ever made using R, and it probably took me 30+ minutes to make, troubleshoot and figure it all out:\n\n\n\n\nThe satisfaction of this and praise really got me motivated to keep going. After I got tired of box plots, I wanted to plot crime data on a map. This was a big part of my learning as I was a criminology concentration within sociology, so it was very applicable to what I liked. I found crime data and shape files from the City of Atlanta and that is how I spent my summer in 2021.\nHere is one of the ‚Äúfinal‚Äù versions of the homicide map for Atlanta, GA:\n\n\n\n\nAfter summer I took a break from R during my last semester at Winthrop and picked it back up in December 2021.\nI do not have many visuals from this time saved as I was working on learning the tidyverse and manipulating data. Most of my time was spent watching tutorials and replicating those methods with my own data. I worked on linear regression, t-tests, and learning functions.\nHere is one visual I found from this time:\n\n\n\n\nFast forward to February 2022, I started working at Topgolf, and I worked from 5am-1pm and spent most my time after work using and learning R. I kept trying to find data around me at work to analyze when I got home. I watched days worth of tutorials and kept up the grind. I decided I was very serious about data and in June I enrolled in Thinkful‚Äôs Data Analytics bootcamp.\nMy time at Thinkful was great, I had an awesome mentor and would come home from Topgolf and learned more about using Excel, SQL, Tableau, and finally Python. I did all of this while still working 5am-1pm and once I completed my daily Thinkful lessons I opened up RStudio and continued learning. In July is when I started using GitHub in a more serious way, and I liked to try to contribute R code everyday to continue learning.\nI will not lie, looking back I am surprised I was able to stay quite motivated doing so much everyday. I definitely would feel burnt out here and there but I wanted to improve my craft. My mentor really kept me motivated and in a true learning mindset. Yaron is a data analyst, and my mentor. His background in Python was great for me to learn it from him. I would also send him R scripts and he would send me Python scripts from our projects we were working on. This was a very cool experience and we really motivated each other in the data and learning realms.\nHere‚Äôs one of my R visuals from this time period:\n\n\n\n\nI was getting better and learning more, however with my perfectionist mindset I created a new GitHub account because I missed a daily contribution while on vacation. I have since come to terms with this, as it is not good to force progress with such high work loads, however this was one of my motivation factors at the time.\n\n\n\n\n\nIn October of 2022 I was promoted to IT Team Lead at Topgolf, and in the following December I graduated the Thinkful program. From here I began really improving my learning of R, I had a playlist of tutorials on YouTube saved and I continued finding projects to work on. I decided one way to learn and continue was TidyTuesday, which is a weekly social data project where a new dataset is posted every Tuesday, and using the tidyverse framework you clean, wrangle and visualize the data with R. My new years resolution for 2023 is to do every TidyTuesday this year. So far I am on track for this goal and this community is awesome!\nYou can view my TidyTuesday visuals here on my website or on my GitHub here.\nMoving on to now, I have been able to continue learning R working on various projects and visuals. I still watch tutorials and read books related to R but I found reading code to be very helpful in learning. When I see a visual I like, or something I want to know how to do when viewing R visuals on Twitter or LinkedIn I look at the creators code. Often times people share the code on GitHub or if you ask, and this has really helped me progress and learn many different ways to approach visualizing data or wrangling data.\nWhen I see a data visual I like, I save a picture of it in a local folder. I do this as a way to keep track of things that can inspire me or motivate me. I found this as another way to learn or ‚Äúkeep things fresh‚Äù.\nNow my most recent visual:\n\n\n\n\nIt is crazy to see my progress over this time frame, and it is hard to realize in the moment. It really takes looking at my plots over time and seeing the results. This is another thing I found helpful‚Ä¶\nSAVE EVERYTHING. I wish I saved more in the past, but being able to look back at an old script, or old visual can show you your progress but also help you stay motivated."
  },
  {
    "objectID": "blog/02-r/index.html#conclusion",
    "href": "blog/02-r/index.html#conclusion",
    "title": "Teaching myself R",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion I think these are the most helpful things in my journey of learning R (in no specific order):\n\nDoing relevant projects\n\nWhatever is on your mind, interests you, or applicable to a role you want\n\nTutorials\n\nFollowing along is fine at first, but try using tutorials as a reference to apply methods to your own projects\n\nMaking mistakes\n\nBeing in the code editor as much as possible\n\nAvoid learning alone\n\nThis can be hard, but finding learning communities, posting updates, having a mentor or friend is very helpful for feedback and support\n\nTaking breaks\n\nMaking time for family, friends, and yourself‚Ä¶\n\nSetting goals\n\nMake them realistic and personal, also do not compare yourself to others and their work, you are your hardest critic, and learning does not happen over night.\n\n\nMy girlfriend and mom both remind me of the progress I have made and how ‚ÄúRome was not built in a day‚Äù, and this is true.\nThe last thing I found very influential was from a video about creating reports with Quarto on YouTube.\n\nIf you do something, and do not share it or talk about it, it is like it does not exist.\n\nWhile this seems obvious, it was something that once I heard I took to heart and what motivated me to make this blog."
  },
  {
    "objectID": "blog/03-topgolf/index.html",
    "href": "blog/03-topgolf/index.html",
    "title": "Simulating Topgolf with R",
    "section": "",
    "text": "It all started with wanting to do a Topgolf related project‚Ä¶ I created the field and targets by drawing shapes with colors in R. My next step was to plot golf balls where they landed. I was met with the tough realization and conclusion that without very tedious and manual data collection, this would not be possible. I was motivated to collect my own data, however over time I would be burnt out and this fun project would become more like a chore. This is when I thought about simulating synthetic data."
  },
  {
    "objectID": "blog/03-topgolf/index.html#synthetic-data",
    "href": "blog/03-topgolf/index.html#synthetic-data",
    "title": "Simulating Topgolf with R",
    "section": "Synthetic Data",
    "text": "Synthetic Data\nSynthetic data may sound weird, but it is actually something that is very useful. In cases where there are privacy concerns (credit cards, customer data, etc‚Ä¶), testing models, and even my case (avoiding tedious work that would be neat but also could burn me out). There are some Python libraries such as Faker that has functions to produce data sets with names, credit card numbers, orders and anything, but it is all synthetic data. This synthetic data can be ‚Äútuned‚Äù to your needs, so you can sample names from a particular geographic area. Allowing you to create customized and realistic distributions of fake data."
  },
  {
    "objectID": "blog/03-topgolf/index.html#simulating-a-game-of-topgolf",
    "href": "blog/03-topgolf/index.html#simulating-a-game-of-topgolf",
    "title": "Simulating Topgolf with R",
    "section": "Simulating a Game of Topgolf",
    "text": "Simulating a Game of Topgolf\nTopgolf has many different game modes that one can play, and I chose to simulate the classic ‚ÄúTopgolf‚Äù game mode. In this mode you get 20 golf balls, and aim for any of the targets. When a ball goes into a target then you score points, and the further targets are worth more points, however you get the most points by hitting into the most center areas of the target. Of course to simulate the game you must first have the field and targets.\n\nCreating the field\nAs previously mentioned I created the field by first drawing out circles to represent the targets. I did this with ggplot and here is what I started with:\n\n\n\nNext I created the back trench target which was a simple rectangle. Once I got all of the targets in place I gave them their respective colors and started looking to methods for creating random data.\n\n\nCreating the data\nI ended up going with the runif() function in R to create my simulated data. I picked this function as I could specify the number of values I wanted to output, the minimum value and the maximum value. From there it would generate a random vector of numbers within my set min and max values. I had two runif() functions, one for the x coordinates of the simulated golf balls and one for the y coordinates.\nFor the first visual I made, I simulated balls randomly within the bounds of the field and then created this heatmap:\n\n\n\nAfter playing around with the visual aesthetics and adjusting the values for creating the sythetic data I was left with this final version:\n\n\n\n\n\nAutomation and ‚Äúbots‚Äù\nHowever, this is only the final version of the visual‚Ä¶ Currently I‚Äôm using R and GitHub Actions to create a bot that will play games of Topgolf at set schedules and report the game‚Äôs results. As of the writing of this blog post, the bot is working and plays a new game every day. Right now it plays the default Topgolf game mode, which gives 20 balls to hit into any of the targets.\nIn addition to playing a game each day, the bot makes a random decision on what club it will use for the 20 balls it hits. Currently the club choice will determine the distance of where the balls can be hit. So a driver will allow for the bot to hit the back targets, and a pitching wedge will only hit out to the green targets.\nThere is not a scoring system implemented yet, but I have already created the code and confirmed that I can detect if a ball scores in a target, and which target it scores in. My next step is to implement the scoring system with this and create a virtual scorecard that will update with each game.\nClick here to check out my bot‚Äôs most recent game, and I will be updating this blog post as I implement more features!"
  },
  {
    "objectID": "blog/04-d3/index.html",
    "href": "blog/04-d3/index.html",
    "title": "D3.js with R",
    "section": "",
    "text": "Neolithic Founder Crops\nThis data is from TidyTuesday week 16 and I thought it would be neat to find a way to visualize it via D3.js within R. I used the networkD3 package to create this radial network visual that shows 3 of the different founder crop categories, and breaks it down to genus.\nThe data wrangling took a while as I had to figure out how to get the lists to work‚Ä¶ After some trial and error I found that someone had posted a R function that could help wrangle data into the specific way you need it. Here is that function:\nrsplit <- function(x) {\n  x <- x[!is.na(x[,1]),,drop=FALSE]\n  if(nrow(x)==0) return(NULL)\n  if(ncol(x)==1) return(lapply(x[,1], function(v) list(name=v)))\n  s <- split(x[,-1, drop=FALSE], x[,1])\n  unname(mapply(function(v,n) {if(!is.null(v)) list(name=n, children=v) else list(name=n)}, lapply(s, rsplit), names(s), SIMPLIFY=FALSE))\nThis rsplit() function will essentially allow you to apply it to objects to get the sublisted outputs. Once you have the output you can simply use the networkD3 functions to create one of these visuals. I had to use this function multiple times for each of the different crop categories, and then put it all into a data frame to prepare my data.\nFinally I had the visual I wanted except for the colors‚Ä¶ After more research I ended up finding this bit of code that allowed me to apply custom colors using js on the back end.\ncolorVector <- c(rep(\"#96B48C\", 235))\n\njsarray <- paste0('[\"', paste(colorVector, collapse = '\", \"'), '\"]')\nnodeStrokeJS <- JS(paste0('function(d, i) { return ', jsarray, '[i]; }'))\nI‚Äôm happy with the end result, it is dynamic so the text grows when you mouse over it. I think this was a good way to get introduced to some D3 within the R environment. I do think with all of the nodes and text is a bit busy, and I would like in the future to do some highlighting of specific paths. Also I searched and tried some ways to make the visual larger, but could not find a solution. However, overall this little experiment was more of a ‚Äúproof of concept‚Äù and way to get me exposed more to the dynamic aspects of visualizing data.\nMy goals moving forward are to continue learning and expanding my knowledge (even beyond R) in order to create more dynamic and insightful visuals. I want to do more with D3, SQL, and Python so working within those tools is next up!\n\n\nCode\n# load packages\npacman::p_load(tidyverse,\n               networkD3,\n               igraph,\n               htmltools)\n\n# load data\nfounder_crops <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-04-18/founder_crops.csv')\n\n# wrangle data\n# categories <- founder_crops |>\n#   select(taxon_source, category) |>\n#   group_by(category) |>\n#   count() |>\n#   arrange(desc(n)) |>\n#   drop_na()\n\ngrasses <- founder_crops |>\n  filter(category == \"Grasses\") |>\n  group_by(category, edibility, genus) |>\n  count() |>\n  arrange(desc(n)) |>\n  mutate(edibility = case_when(edibility = is.na(edibility) ~ \"Not Edible\",\n                               .default = \"Edible\"))\n\nwild_plants <- founder_crops |>\n  filter(category == \"Wild plants\") |>\n  group_by(category, edibility, genus) |>\n  count() |>\n  arrange(desc(n)) |>\n  mutate(edibility = case_when(edibility = is.na(edibility) ~ \"Not Edible\",\n                               .default = \"Edible\"))\n\npulses <- founder_crops |>\n  filter(category == \"Pulses\") |>\n  group_by(category, edibility, genus) |>\n  count() |>\n  arrange(desc(n)) |>\n  mutate(edibility = case_when(edibility = is.na(edibility) ~ \"Not Edible\",\n                               .default = \"Edible\"))\n\nfruits <- founder_crops |>\n  filter(category == \"Fruits/nuts\") |>\n  group_by(category, edibility, genus) |>\n  count() |>\n  arrange(desc(n)) |>\n  mutate(edibility = case_when(edibility = is.na(edibility) ~ \"Not Edible\",\n                               .default = \"Edible\")) |>\n  select(-n)\n\n\nrsplit <- function(x) {\n  x <- x[!is.na(x[,1]),,drop=FALSE]\n  if(nrow(x)==0) return(NULL)\n  if(ncol(x)==1) return(lapply(x[,1], function(v) list(name=v)))\n  s <- split(x[,-1, drop=FALSE], x[,1])\n  unname(mapply(function(v,n) {if(!is.null(v)) list(name=n, children=v) else list(name=n)}, lapply(s, rsplit), names(s), SIMPLIFY=FALSE))\n}\nsplit_g <- rsplit(grasses)\nsplit_wp <- rsplit(wild_plants)\nsplit_f <- rsplit(fruits)\nsplit_p <- rsplit(pulses)\n\ntest <- list(name = \"Founder Crops\", children = c(split_g,  split_p, split_wp))\ndiagonal_plot <- diagonalNetwork(List = test, fontSize = 10, opacity = 0.9)\n\n\ncolorVector <- c(rep(\"#96B48C\", 235))\n\njsarray <- paste0('[\"', paste(colorVector, collapse = '\", \"'), '\"]')\nnodeStrokeJS <- JS(paste0('function(d, i) { return ', jsarray, '[i]; }'))\nradial_plot <- radialNetwork(List = test, fontSize = 12, opacity = 0.95, linkColour = nodeStrokeJS, nodeColour = nodeStrokeJS,\n              nodeStroke = nodeStrokeJS, textColour = \"#0f120e\")\n\nradial_plot"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\n\n\n\n\n4/19/23\n\n\nD3.js with R\n\n\n\n\n3/27/23\n\n\nSimulating Topgolf with R\n\n\n\n\n3/14/23\n\n\nTeaching myself R\n\n\n\n\n3/3/23\n\n\nWhy Quarto?\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bradford Johnson",
    "section": "",
    "text": "Data Analyst\n\n\n\n\n\n\n\nInterested in connecting or talking data? Use the buttons below to contact me!\n\n\n\n\n \n  \n   \n  \n    \n     LinkedIn\n  \n  \n    \n     GitHub\n  \n  \n    \n     Tableau\n  \n  \n    \n     Email\n  \n  \n    \n     Twitter"
  },
  {
    "objectID": "index.html#fa-chart-column-visual-gallery",
    "href": "index.html#fa-chart-column-visual-gallery",
    "title": "Bradford Johnson",
    "section": " Visual Gallery",
    "text": "Visual Gallery\nClick on an image to view the source code!"
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Bradford Johnson",
    "section": "Projects",
    "text": "Projects\nClick here to check out my latest projects.\n\n\n\n\n  \n\n\n\n\nSeinfeld Scripts\n\n\n\n\n\nText analysis of scripts from the TV series Seinfeld\n\n\n\n\n\n\nMar 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nVending Machine Sales\n\n\n\n\n\nAnalysis on trends among various vending machines and optimizing their stocking methods\n\n\n\n\n\n\nDec 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nFuel Economy\n\n\n\n\n\nStatistical analysis on factors that drive fuel cost and consumption\n\n\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#blog",
    "href": "index.html#blog",
    "title": "Bradford Johnson",
    "section": "Blog",
    "text": "Blog\nClick here see my latest blog posts.\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nApr 19, 2023\n\n\nD3.js with R\n\n\n\n\nMar 27, 2023\n\n\nSimulating Topgolf with R\n\n\n\n\nMar 14, 2023\n\n\nTeaching myself R\n\n\n\n\nMar 3, 2023\n\n\nWhy Quarto?\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/fuel-economy/index.html",
    "href": "projects/fuel-economy/index.html",
    "title": "Fuel Economy",
    "section": "",
    "text": "Statistical Significance | Fuel Economy"
  },
  {
    "objectID": "projects/fuel-economy/index.html#project-summary",
    "href": "projects/fuel-economy/index.html#project-summary",
    "title": "Fuel Economy",
    "section": "Project Summary üóíÔ∏è",
    "text": "Project Summary üóíÔ∏è\n\nüß≠- Project scenario\n\nProvide data-backed analysis and recommendations around vehicle fuel economy\nClient is interested in vehicle types, manufacturers, and technical specs\nThey want to understand how those might drive fuel economy and annual fuel costs\n\n\n\n\n\n\n\nProject Objective\n\n\n\n\nIdentify and conduct statistical tests on factors that drive fuel economy and annual costs\n\n\n\n\n\nüìÇ- Deliverables\nClick the icons or text below to see my project files and deliverables\n\n\n\nPowerPoint\nExcel\n\n\n\n\n\n\n\n\n\n\n\nüîß- Methods\n\n\n\n\n\n\nResearch Questions\n\n\n\n\nDoes the Start / Stop Technology make a significant difference in fuel costs / consumption?\n\n\nDoes the car‚Äôs ‚Äúage‚Äù or model year have a significant difference in fuel economy?\n\n\nHow significant is the car‚Äôs class (car type: minivan, truck, compact‚Ä¶) in the consumption of fuel?\n\n\n\n\nMost vehicles use regular gas as a fuel type -> focus on regular gas vehicles\n\nRegular gas is convenient, and already has nationwide infrastructure\n\nSubcompact and compact vehicles are the most common classes -> focus on these car classes\n\nThese two classes are the most popular and they are quite similar in specific metrics\n\nCar ‚Äúage‚Äù determined by the model year -> focus on new vs used\n\n\n\n\nüîç- Findings\n\n\nStart Stop Technology - Fuel Cost\n\n\n\nCar Class - Combined MPG\n\n\n\nCar Age - Used Fuel Quantity\n\n\n\n5 Year Savings and Spending\n\n\n\nüí°- Recommendations\n\nFor fuel economy and savings, without sacrificing the convenience of regular gas, use cars with Start / Stop Technology\nPrioritize using newer cars (2015 and newer) as on average they have a significantly better combined MPG than older counterparts\nImplementing the above and using the compact vehicle class will offer the best savings in terms of fuel economy"
  },
  {
    "objectID": "projects/lariat-rentals/index.html",
    "href": "projects/lariat-rentals/index.html",
    "title": "Lariat Rentals",
    "section": "",
    "text": "Rental fleet business analysis | Revenue growth model"
  },
  {
    "objectID": "projects/lariat-rentals/index.html#project-summary",
    "href": "projects/lariat-rentals/index.html#project-summary",
    "title": "Lariat Rentals",
    "section": "Project Summary üóíÔ∏è",
    "text": "Project Summary üóíÔ∏è\n\nüß≠- Project scenario\n\nI am consulting as a data analyst for Lariat\nThey hired me to make suggestions on how they can make smarter business decisions\nMy job is to analyze the costs and revenue generated by their rental car fleet\nThey provided me the data for their nationwide, 4,000-car fleet\n\n\n\n\n\nLariat‚Äôs Business Objective\n\n\n\n\nMinimizing costs and maximizing revenue\n\n\n\n\n\n\nüìÇ- Deliverables\nClick the icons or text below to see my project files and deliverables\n\n\n\nPowerPoint\nExcel\n\n\n\n\n\n\n\n\n\n\n\n\nüîß- Methods\n\nData cleaning and exploration\nDefining parameters\n\n\nGroup vehicles by model year for baseline\n\nBreak down ‚Äúthe numbers‚Äù to the daily level (ex. Revenue per day, cost per day‚Ä¶)\n\n\n\nCreate a user scenario that can take custom values and apply them to the baseline\n\n\n\n\nüîç- Findings\n\nThe top 4 most popular car makes: Ford, Chevrolet, Dodge, and Toyota\n\n\nThese 4 car makes account for over ¬º of the rental fleet\n\n\nThe daily revenue and cost per car does not vary much by model year\n\nTotal rental days is not significantly different among the 3 different car model years\n\n\n\n\nüí°- Recommendations\n\nMinimizing Costs\n\nRetire and sell high-cost, low return vehicles\nReplace with more popular and higher revenue make/models\n\nMaximizing Revenue\n\nIncrease the prices for rentals\nWhen doing this assume a decrease in total days rented"
  },
  {
    "objectID": "projects/seinfeld/index.html",
    "href": "projects/seinfeld/index.html",
    "title": "Seinfeld Scripts",
    "section": "",
    "text": "Sentiment analysis of Seinfeld scripts\n\nPositive and negative sentiments across different lexicons\n\nIdentify ‚Äúcatchphrases‚Äù, common themes, and inside jokes\n\nWord frequency and relationships\n\nWord correlation\n\nHow are certain words related?\n\nWrangle and visualize insightful relationships‚Ä¶\n\n\n\n\n\n\n\nSeparate processes into dedicated R scripts and ‚Äòstages‚Äô:\n\nIndividual R file for each data prep / wrangling / cleaning task\nSave wrangled and cleaned data frames as .csv‚Äôs\nLoad prepared data into dedicated visualization scripts\nSave individual visuals and final visuals\n\n\nThis workflow is done in stages for the following reasons:\n\nLighten the workload on a machine | lots of text in these data sets\nMaintain an organized work environment\nPrepared data can be saved and used in the future | version control\nErrors can be isolated\n\n\n\n\n\nunnest_tokens() | Separate text into rows of single words\nanti_join() | Drop uninteresting words (stop words)\nget_sentiment() | Evaluating 3 different lexicons:\n\nBing\nNRC\nAFINN\n\n\n\n\n\n\nBigrams: Pairs of consecutive words grouped by character with counts\n\n\nunnest_tokens(bigram) | Separate text into rows of two words\nfilter() | Remove common stop words and selected words\ncount() | Get counts of bigrams\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to use lexicons and ‚Äútune‚Äù them for a specific need\nHow to filter words like stop words, and customize the lists of words\nUsing bigrams, trigrams, and correlation to identify common themes and trends\nHow to implement these methods to paint the bigger picture\n\n\n\n\n\n\n\nSeinfeld data\n\n\n\n\n\nFinn √Örup Nielsen A new ANEW: Evaluation of a word list for sentiment analysis in microblogs. Proceedings of the ESWC2011 Workshop on ‚ÄòMaking Sense of Microposts‚Äô: Big things come in small packages 718 in CEUR Workshop Proceedings 93-98. 2011 May. https://arxiv.org/abs/1103.2903.\nMinqing Hu and Bing Liu, ‚ÄúMining and summarizing customer reviews.‚Äù, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD-2004), 2004.\nMohammad, S.M. and Turney, P.D. (2013), CROWDSOURCING A WORD‚ÄìEMOTION ASSOCIATION LEXICON. Computational Intelligence, 29: 436-465. https://doi.org/10.1111/j.1467-8640.2012.00460.x"
  },
  {
    "objectID": "projects/vending-machines/index.html",
    "href": "projects/vending-machines/index.html",
    "title": "Vending Machine Sales",
    "section": "",
    "text": "Python Data Analysis | Vending Machine Sales"
  },
  {
    "objectID": "projects/vending-machines/index.html#project-summary",
    "href": "projects/vending-machines/index.html#project-summary",
    "title": "Vending Machine Sales",
    "section": "Project Summary üóíÔ∏è",
    "text": "Project Summary üóíÔ∏è\n\nüß≠- Project scenario\n\nUse Python and pandas to explore a dataset and ultimately craft an analysis for a final presentation\nCreate a notebook demonstrating a clear story about the research question, the hypothesis, and the results of testing it\nPresent findings and analysis process with a slide deck\n\n\n\n\n\nDataset Used\n\n\n\n\nVending Machine Sales from Kaggle\n\n\n\n\n\n\nüìÇ- Deliverables\nClick the icons or text below to see my project files and deliverables\n\n\n\nJupyter Notebook\nPowerPoint\nProject Proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\nüîß- Methods\n\nData cleaning and exploration using Python\nPandas, NumPy, seaborn, etc.\n\n\n\n\n\n\nResearch Questions\n\n\n\n\n\nWhat product categories generate the most revenue on average?\n\nHow can the product selection be optimized to increase revenue?\n\n\n\n\n\nWhat vending machine locations generate the most sales?\n\nHow can vending machines be optimized by location?\n\n\n\n\n\n\n\n\n\nüîç- Findings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüí°- Recommendations\n\nOverall\n\nSpace is limited | Optimize the space used and customize the selection based on location\n\nCondense product selection to meet consumer preferences to increase revenue\nBalance selection and variety to lower costs for buying in bulk (economy of scale)\nLocations where people work or spend lots of time tend to have more purchases\n\n\n\n\nLocation Specific\n\nBrunswick Sq Mall\n\nKeep only the ‚ÄòATT‚Äô vending machine\nAllocate the majority of space for food and water options, with the carbonated and non-carbonated options only being for the most popular overall products\n\nEarle Asphalt\n\nMajority of options should be food products\nWater, carbonated and non-carbonated options only being the most popular for this location\n\nGutten Plans\n\nMajority of options should be food and carbonated drink products\nNon-carbonated options should only be the most popular for this location\nTest with the most popular water products to see if this option is in demand\n\nEB Public Library\n\nMajority of vending products should be food\nStock popular carbonated drinks and non-carbonated product options\nOnly the most popular water products should be stocked at this location"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Seinfeld Scripts\n\n\n\n\n\n\n\nSentiment\n\n\nText Analysis\n\n\n\n\nText analysis of scripts from the TV series Seinfeld\n\n\n\n\n\n\nMar 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nVending Machine Sales\n\n\n\n\n\n\n\nThinkful Capstone\n\n\n\n\nAnalysis on trends among various vending machines and optimizing their stocking methods\n\n\n\n\n\n\nDec 10, 2022\n\n\n\n\n\n\n  \n\n\n\n\nFuel Economy\n\n\n\n\n\n\n\nThinkful Capstone\n\n\n\n\nStatistical analysis on factors that drive fuel cost and consumption\n\n\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLariat Rentals\n\n\n\n\n\n\n\nThinkful Capstone\n\n\n\n\nData analysis and model creation for maximizing revenue and minimizing costs\n\n\n\n\n\n\nSep 5, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tidytuesday.html",
    "href": "tidytuesday.html",
    "title": "TidyTuesday",
    "section": "",
    "text": "Every Tuesday a new dataset is featured for the community to clean, wrangle and visualize. All focused within the tidyverse framework in R!\n\n\n\n\nHere are my TidyTuesday Visuals for 2023!\n\n\n\n\n\n\n01/03/23 | Bring your own data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01/10/23 | Bird FeederWatch data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01/17/23 | Art History data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01/24/23 | Alone TV Series data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01/31/23 | Pet Cats UK data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02/07/23 | Tech Stocks data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02/14/23 | Hollywood age gap data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02/21/23 | Bob Ross Paintings data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02/28/23 | African language sentiment data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03/07/23 | Numbats in Australia data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03/14/23 | European drug development data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03/21/23 | Programming languages data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03/28/23 | Time zones data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04/04/23 | Premier League Match data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04/11/23 | US Egg Production data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04/18/23 | Neolithic Founder Crops data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04/25/23 | London Marathon data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05/02/23 | The Portal Project data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05/09/23 | Childcare Costs data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05/16/23 | Tornados data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05/23/23 | Central Park Squirrels data"
  }
]